<!DOCTYPE html>
<html>
<head>
  <meta name="google-site-verification" content="Io5PBEGCOEzWaL7oGOG-6-qHqYLZsvb7vAXvdoEF-1Y" />
  <meta name="msvalidate.01" content="D97AB8CB8C1A3EA2683CC95DBCD5B305" />
  <meta charset="utf-8">
  <meta name="description"
        content="Robotic grasping in scenes with transparent and specular objects presents great challenges for methods relying on accurate depth information. In this paper, we introduce NeuGrasp, a neural surface reconstruction method that leverages background priors for material-agnostic grasp detection. NeuGrasp integrates transformers and global prior volumes to aggregate multi-view features with spatial encoding, enabling robust surface reconstruction in narrow and sparse viewing conditions. By focusing on foreground objects through residual feature enhancement and refining spatial perception with an occupancy-prior volume, NeuGrasp excels in handling objects with transparent and specular surfaces. Extensive experiments in both simulated and real-world scenarios show that NeuGrasp outperforms state-of-the-art methods in grasping while maintaining comparable reconstruction quality.">
  <meta name="keywords" content="NeuGrasp, GraspNeRF, NeRF, neural surface reconstruction, neural radiance field, transparent object grasping, 6-DoF grasp detection, background priors, AI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>NeuGrasp</title>

  <!--   Global site tag (gtag.js) - Google Analytics -->
  <!-- 引入Google Analytics脚本，用于跟踪网页的访问数据。 -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- 引入外部字体和CSS样式文件，用于美化网页。 -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/Fig1_600.png">

  <!-- 引入jQuery和FontAwesome等JavaScript库，用于增强网页的功能和交互性。 -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- 创建一个导航栏，包含主页链接和更多研究项目的下拉菜单 -->
<nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>
    <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
            <a class="navbar-item" href="https://fanqyu.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
            </a>

            <!--      <div class="navbar-item has-dropdown is-hoverable">-->
            <!--        <a class="navbar-link">-->
            <!--          More Related Research-->
            <!--        </a>-->
            <!--        <div class="navbar-dropdown">-->
            <!--          <a class="navbar-item" href="https://pointw.github.io/equi_rl_page/">-->
            <!--            Equivairant Reinforcement Learning-->
            <!--          </a>-->
            <!--          <a class="navbar-item" href="https://pointw.github.io/equi_q_page/">-->
            <!--            Equivariant Q-Learning-->
            <!--          </a>-->
            <!--          <a class="navbar-item" href="https://pointw.github.io/equi_robot_page/">-->
            <!--            On Robot Equivariant Learning-->
            <!--          </a>-->
            <!--          <a class="navbar-item" href="https://pointw.github.io/extrinsic_page/">-->
            <!--            Extrinsic Equivariance-->
            <!--          </a>-->
            <!--        </div>-->
            <!--      </div>-->
        </div>

    </div>
</nav>

<!-- 展示研究项目的标题、作者、链接（论文、arXiv、视频、代码和数据） -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">NeuGrasp: Generalizable Neural Surface Reconstruction with Background Priors for Material-Agnostic Object Grasp Detection</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://fanqyu.github.io/">Qingyu Fan</a><sup>1,2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/site/caiyinghao">Yinghao Cai</a><sup>1,2†</sup>,
            </span>
            <span class="author-block">
              Chao Li<sup>3</sup>,
            </span>
            <span class="author-block">
              Wenzhe He<sup>3</sup>,
            </span>
            <span class="author-block">
              Xudong Zheng<sup>3</sup>,
            </span>   
            <span class="author-block">
              Tao Lu<sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=mpchz3sAAAAJ&view_op=list_works&sortby=pubdate ">Bin Liang</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=XL9j2UUAAAAJ&hl=en">Shuo Wang</a><sup>1,2</sup>
            </span>  
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences</span><br>
            <span class="author-block"><sup>2</sup>School of Artificial Intelligence, University of Chinese Academy of Sciences</span><br>
            <span class="author-block"><sup>3</sup>Qiyuan Lab</span>
          </div>

          <p>† corresponding author</p>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2503.03511"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.03511"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/jnJgKZYgt28"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Fanqyu/NeuGrasp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/15IVQq2WghkstxXxw54Q3VAaMHXRaBlFz/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
      <div class="hero-body" style="text-align: center;">
        <img src="./static/images/Fig1-2_300.png" alt="Teaser Image" width="60%" /><br>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="content has-text-justified">
                <p>
                  <strong>Fig. 1. Overview of NeuGrasp.</strong> We introduce a generalizable method that utilizes background priors within a neural implicit surface framework to achieve real-time scene reconstruction and material-agostic grasping from observations within a narrow field of view.
                </p>
              </div>
            </div>
          </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-4 has-text-centered">NeuGrap</h2>
      
      <div id="results-carousel" class="carousel results-carousel">
        
        <!-- VIDEOS -->
        <div class="item item-steve">
          <video poster="" id="transparent" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/transparent_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="pile2" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/pile2_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="packed2" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/packed2_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="pile1" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/pile1_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="packed1" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/packed1_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="packed4" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/packed4_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="packed6" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/packed6_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="packed5" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/packed5_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="packed3" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp/packed3_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

  

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-4 has-text-centered">NeuGrap-RA</h2>
      
      <div id="results-carousel" class="carousel results-carousel">
        
        <!-- VIDEOS -->
        <div class="item item-steve">
          <video poster="" id="transparent" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/transparent_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="specular" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/specular_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="pile6" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/pile6_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="pile7" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/pile7_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="packed4" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/packed4_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="packed3" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/packed3_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="packed1" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/packed1_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="pile1" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/pile1_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="pile2" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/pile2_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="pile4" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/pile4_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="pile5" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/pile5_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="packed2" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/packed2_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="packed5" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/packed5_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="packed6" autoplay controls muted loop playsinline height="25%">
            <source src="./static/videos/NeuGrasp-RA/packed6_cmprs.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Robotic grasping in scenes with transparent and specular objects presents great challenges for methods relying on accurate depth information. In this paper, we introduce NeuGrasp, a neural surface reconstruction method that leverages background priors for material-agnostic grasp detection. NeuGrasp integrates transformers and global prior volumes to aggregate multi-view features with spatial encoding, enabling robust surface reconstruction in narrow and sparse viewing conditions. By focusing on foreground objects through residual feature enhancement and refining spatial perception with an occupancy-prior volume, NeuGrasp excels in handling objects with transparent and specular surfaces. Extensive experiments in both simulated and real-world scenarios show that NeuGrasp outperforms state-of-the-art methods in grasping while maintaining comparable reconstruction quality.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/jnJgKZYgt28?si=b52EHjr_yBXgXRFi"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
<!--           <video poster="" id="toby" controls muted loop playsinline height="100%">
            <source src="./static/videos/NeuGrasp_1080_compressed2.mp4"
                    type="video/mp4"> -->
          </video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

    <!--     Method -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <img src="./static/images/Fig2_600.png" alt="Teaser Image" width="100%" /><br>
          <div class="columns is-centered has-text-centered">
            <div class="content has-text-justified">
              <p>
                <strong>Fig. 2. Framework of NeuGrasp.</strong> NeuGrasp leverages background priors for neural surface reconstruction and material-agnostic grasp detection. A Residual Feature Enhancement module is proposed to enhance the model attention on foreground objects instead of irrelevant background information. We build an occupancy-prior volume from residual features and a shape-prior volume from scene features. These volumes are then combined with multi-view features using Residual and Source View Transformers, which are further refined by a Ray Transformer to capture geometric details. The resulting unified view feature and attention-weighted features are decoded into a signed distance function and converted into a radiance field. Finally, the grasping module maps the reconstructed geometry to 6-DoF grasp poses, enabling end-to-end training. 
              </p>
            </div>
          </div>
      </div>
    </div>
    <!--     Method -->
  </div>
</section>

  

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      
    <!-- Concurrent Work. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Acknowledgements</h2>

        <div class="content has-text-justified">
          <p>
            We would like to thank the authors of <a href="https://github.com/ethz-asl/vgn">VGN</a> and <a href="https://pku-epic.github.io/GraspNeRF/\">GraspNeRF</a> for making their work publicly available.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>

<!-- BIBTEX_REFERENCE_DATA -->
<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Qingyu Fan, Yinghao Cai, Chao Li, Wenzhe He, Xudong Zheng, Tao Lu, Bin Liang, Shuo Wang},
  title     = {NeuGrasp: Generalizable Neural Surface Reconstruction with Background Priors for Material-Agnostic Object Grasp Detection},
  journal   = {XXXX},
  year      = {2025},
}</code></pre>
  </div>
</section> -->



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      
    <!-- Contact. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Contact</h2>

        <div class="content has-text-justified">
          <p>If you have any questions, please feel free to contact us:</p>
          <ul>
            <li><strong>Qingyu Fan</strong>: <a href="mailto:fanqingyu23@mails.ucas.ac.cn">fanqingyu23@mails.ucas.ac.cn</a></li>
            <li><strong>Yinghao Cai</strong>: <a href="mailto:yinghao.cai@ia.ac.cn">yinghao.cai@ia.ac.cn</a></li>
          </ul>
        </div>
      </div>
    </div>
    <!--/ Contact. -->

  </div>
</section>

  

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="RELATICE_LINK_TO_PDF">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/Fanqyu" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
